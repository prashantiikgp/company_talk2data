{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f267d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prashant-agrawal/Netflix_Project/src\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import sys, os\n",
    "SRC_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\",\"..\",\"src\"))\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "print(SRC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faf73e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: /home/prashant-agrawal/Netflix_Project/src\n",
      "CSV Path: /home/prashant-agrawal/Netflix_Project/src/Data/Enriched_Indian_Startup_Dataset.csv\n",
      "Qdrant Local Path: /home/prashant-agrawal/Netflix_Project/src/database/qdrant_store_local_db/collection\n",
      "Qdrant Collection Name: indian_startups\n",
      "Schema Output Path: /home/prashant-agrawal/Netflix_Project/src/schema/payload_schema.json\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams, Distance, PayloadSchemaType\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from utils.qdrant_client_loader import get_qdrant_collection_name\n",
    "from utils.path_config import get_base_dir, get_data_path, get_qdrant_store_path, get_schema_path\n",
    "\n",
    "\n",
    "# ðŸ“ Paths\n",
    "BASE_DIR = get_base_dir()\n",
    "print(f\"Base Directory: {BASE_DIR}\")\n",
    "\n",
    "DATA_PATH = get_data_path()\n",
    "print(f\"CSV Path: {DATA_PATH}\")\n",
    "\n",
    "qdrant_store_path = get_qdrant_store_path()\n",
    "print(f\"Qdrant Local Path: {qdrant_store_path}\")\n",
    "\n",
    "COLLECTION_NAME = get_qdrant_collection_name()\n",
    "print(f\"Qdrant Collection Name: {COLLECTION_NAME}\")\n",
    "\n",
    "SCHEMA_OUTPUT_PATH = get_schema_path()\n",
    "print(f\"Schema Output Path: {SCHEMA_OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b28fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams, Distance\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def load_documents_from_df(df: pd.DataFrame) -> list:\n",
    "    documents = []\n",
    "    for _, row in df.iterrows():\n",
    "        metadata = row.dropna().to_dict()\n",
    "        content = \"\\n\".join(f\"{k}: {v}\" for k, v in metadata.items())\n",
    "        documents.append(Document(page_content=content, metadata=metadata))\n",
    "    return documents\n",
    "\n",
    "def run_ingestion_pipeline(csv_path: str, collection_name: str):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns]\n",
    "\n",
    "    client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "    # Clean slate\n",
    "    if client.collection_exists(collection_name):\n",
    "        client.delete_collection(collection_name=collection_name)\n",
    "\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\n",
    "    )\n",
    "\n",
    "    documents = load_documents_from_df(df)\n",
    "    Qdrant.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=OpenAIEmbeddings(),\n",
    "        url=\"http://localhost:6333\",\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    print(f\"âœ… Ingested {len(documents)} documents with metadata into Qdrant.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "081a9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest_and_query_qdrant.py\n",
    "\n",
    "def infer_payload_schema_from_df(df: pd.DataFrame) -> dict:\n",
    "    inferred_schema = {}\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dropna().infer_objects().dtype\n",
    "        if pd.api.types.is_integer_dtype(dtype):\n",
    "            inferred_schema[col] = PayloadSchemaType.INTEGER\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            inferred_schema[col] = PayloadSchemaType.FLOAT\n",
    "        else:\n",
    "            inferred_schema[col] = PayloadSchemaType.KEYWORD\n",
    "    return inferred_schema\n",
    "\n",
    "\n",
    "def generate_payload_json(schema: dict, output_path: str):\n",
    "    raw_json = {k: v.value for k, v in schema.items()}\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(raw_json, f, indent=2)\n",
    "    print(f\"ðŸ“„ Saved payload schema to {output_path}\")\n",
    "\n",
    "\n",
    "def load_documents_from_df(df: pd.DataFrame) -> list:\n",
    "    documents = []\n",
    "    for _, row in df.iterrows():\n",
    "        metadata = row.dropna().to_dict()\n",
    "        content = \"\\n\".join(f\"{k}: {v}\" for k, v in metadata.items())\n",
    "        documents.append(Document(page_content=content, metadata=metadata))\n",
    "    return documents\n",
    "\n",
    "\n",
    "def recreate_qdrant_collection(client: QdrantClient, collection_name: str, schema: dict):\n",
    "    if client.collection_exists(collection_name):\n",
    "        client.delete_collection(collection_name=collection_name)\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    "        payload_schema=schema\n",
    "    )\n",
    "    print(f\"âœ… Created collection `{collection_name}` with schema of {len(schema)} fields\")\n",
    "\n",
    "\n",
    "def run_ingestion_pipeline(csv_path: str, collection_name: str, schema_path: str):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns]\n",
    "\n",
    "    # Step 1: Infer & save schema\n",
    "    schema = infer_payload_schema_from_df(df)\n",
    "    generate_payload_json(schema, schema_path)\n",
    "\n",
    "    # Step 2: Create collection\n",
    "    client = QdrantClient(url=\"http://localhost:6333\")\n",
    "    recreate_qdrant_collection(client, collection_name, schema)\n",
    "\n",
    "    # Step 3: Upload documents\n",
    "    documents = load_documents_from_df(df)\n",
    "    Qdrant.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=OpenAIEmbeddings(),\n",
    "        url=\"http://localhost:6333\",\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    print(f\"ðŸš€ Uploaded {len(documents)} documents to Qdrant.\")\n",
    "\n",
    "\n",
    "def run_sample_query(query: str, filters: dict, collection_name: str):\n",
    "    # Step 4: Perform query\n",
    "    client = QdrantClient(url=\"http://localhost:6333\")\n",
    "    qdrant_store = Qdrant(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=OpenAIEmbeddings(),\n",
    "    )\n",
    "\n",
    "    # Convert dictionary filters into Qdrant Filter format\n",
    "    filter_conditions = [FieldCondition(key=k, match=MatchValue(value=v)) for k, v in filters.items()]\n",
    "    qdrant_filter = Filter(must=filter_conditions)\n",
    "\n",
    "    results = qdrant_store.similarity_search_with_score(query=query, k=5, filter=qdrant_filter)\n",
    "\n",
    "    print(\"\\nðŸ“Œ Query Results:\\n\")\n",
    "    for doc, score in results:\n",
    "        print(f\"ðŸ§  Score: {score:.4f}\")\n",
    "        print(doc.page_content)\n",
    "        print(\"-\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd7f252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Saved payload schema to /home/prashant-agrawal/Netflix_Project/src/schema/payload_schema.json\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Unknown arguments: ['payload_schema']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Optional CLI usage\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mrun_ingestion_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOLLECTION_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCHEMA_OUTPUT_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     run_sample_query(\n\u001b[1;32m      6\u001b[0m         query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop funded fintech startups\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m         filters\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39mCOLLECTION_NAME\n\u001b[1;32m     12\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[14], line 54\u001b[0m, in \u001b[0;36mrun_ingestion_pipeline\u001b[0;34m(csv_path, collection_name, schema_path)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Step 2: Create collection\u001b[39;00m\n\u001b[1;32m     53\u001b[0m client \u001b[38;5;241m=\u001b[39m QdrantClient(url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:6333\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mrecreate_qdrant_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Step 3: Upload documents\u001b[39;00m\n\u001b[1;32m     57\u001b[0m documents \u001b[38;5;241m=\u001b[39m load_documents_from_df(df)\n",
      "Cell \u001b[0;32mIn[14], line 36\u001b[0m, in \u001b[0;36mrecreate_qdrant_collection\u001b[0;34m(client, collection_name, schema)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client\u001b[38;5;241m.\u001b[39mcollection_exists(collection_name):\n\u001b[1;32m     35\u001b[0m     client\u001b[38;5;241m.\u001b[39mdelete_collection(collection_name\u001b[38;5;241m=\u001b[39mcollection_name)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVectorParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1536\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDistance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOSINE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpayload_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Created collection `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` with schema of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(schema)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Netflix_Project/venv/lib/python3.10/site-packages/qdrant_client/qdrant_client.py:2384\u001b[0m, in \u001b[0;36mQdrantClient.create_collection\u001b[0;34m(self, collection_name, vectors_config, sparse_vectors_config, shard_number, sharding_method, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, timeout, strict_mode_config, **kwargs)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_collection\u001b[39m(\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2317\u001b[0m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2334\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   2335\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   2336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create empty collection with given parameters\u001b[39;00m\n\u001b[1;32m   2337\u001b[0m \n\u001b[1;32m   2338\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;124;03m        Operation result\u001b[39;00m\n\u001b[1;32m   2383\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2384\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mcreate_collection(\n\u001b[1;32m   2387\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[1;32m   2388\u001b[0m         vectors_config\u001b[38;5;241m=\u001b[39mvectors_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2402\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2403\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Unknown arguments: ['payload_schema']"
     ]
    }
   ],
   "source": [
    "\n",
    "# Optional CLI usage\n",
    "if __name__ == \"__main__\":\n",
    "    run_ingestion_pipeline(DATA_PATH, COLLECTION_NAME, SCHEMA_OUTPUT_PATH)\n",
    "\n",
    "    run_sample_query(\n",
    "        query=\"Top funded fintech startups\",\n",
    "        filters={\n",
    "            \"headquarters_city\": \"Bengaluru\",\n",
    "            \"industry_sector\": \"Fintech\"\n",
    "        },\n",
    "        collection_name=COLLECTION_NAME\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "002fbe16",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'qdrant_client' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mqdrant_client\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mqdrant_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'qdrant_client' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import qdrant_client\n",
    "print(qdrant_client.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
