{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96b11f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SRC path added: /home/prashant-agrawal/projects/netflix_talk2data/src\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import sys, os\n",
    "try:\n",
    "    # ‚úÖ Running from a Python script (.py file)\n",
    "    TOOLS_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__)))\n",
    "except NameError:\n",
    "    # ‚úÖ Running from a Jupyter notebook (__file__ is not defined)\n",
    "    TOOLS_PATH = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "SRC_PATH = os.path.join(TOOLS_PATH)\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "    print(f\"‚úÖ SRC path added: {SRC_PATH}\")\n",
    "else:\n",
    "    print(f\"üîÅ SRC path already in sys.path: {SRC_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503399c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langsmith import Client\n",
    "\n",
    "LANGSMITH_TRACING=True\n",
    "LANGSMITH_ENDPOINT= \"https://api.smith.langchain.com\"\n",
    "LANGSMITH_API_KEY=os.getenv(\"LANGSMITH_API_KEY\") \n",
    "openai.api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set tracing in LangGraph\n",
    "from langchain_core.tracers import ConsoleCallbackHandler\n",
    "callbacks = [ConsoleCallbackHandler()]  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a191ec4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SRC path added: /home/prashant-agrawal/projects/netflix_talk2data/src\n",
      "üîÅ SRC path already in sys.path: /home/prashant-agrawal/projects/netflix_talk2data/src\n",
      "üîÅ SRC path already in sys.path: /home/prashant-agrawal/projects/netflix_talk2data/src\n",
      "üîÅ SRC path already in sys.path: /home/prashant-agrawal/projects/netflix_talk2data/src\n",
      "üîÅ SRC path already in sys.path: /home/prashant-agrawal/projects/netflix_talk2data/src\n",
      "üîÅ SRC path already in sys.path: /home/prashant-agrawal/projects/netflix_talk2data/src\n",
      "üìå Collection Name: indian_startups\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: what to do next\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: what to do next\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: I need to extract relevant keywords from the query.\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: I need to extract relevant keywords from the query.\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: I need to extract relevant keywords from the query.\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: I need to extract relevant keywords from the query.\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: I need to extract relevant keywords from the query.\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: I need to extract relevant keywords from the query.\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: I need to extract relevant keywords from the query.\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: I need to extract relevant keywords from the query.\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: I need to extract relevant keywords from the query.\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n",
      "\n",
      "[DEBUG] Enhancer Node received user_input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] Enhancer payload: {'input': 'Find 5 B2B SaaS startups in India ', 'intermediate_steps': []}\n",
      "[DEBUG] AgentAction: Thought: I need to extract relevant keywords from the query.\n",
      "Action: keyword_extractor\n",
      "Action Input: Find 5 B2B SaaS startups in India \n",
      "[DEBUG] raw final_output: None\n",
      "[DEBUG] Parsed enhanced_query: \n",
      "[DEBUG] Parsed filters: {}\n",
      "[DEBUG] Parsed k: None\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     25\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFind 5 B2B SaaS startups in India \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Final State ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnhanced Query   : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menhanced_query\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m, in \u001b[0;36mrun_once\u001b[0;34m(user_query)\u001b[0m\n\u001b[1;32m     14\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [ {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_query} ]\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 3) Invoke the graph synchronously (follows supervisor‚Üíenhancer‚Üísearch‚ÜíEND)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m final_state \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 4) Inspect or return the final state\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_state\n",
      "File \u001b[0;32m~/projects/netflix_talk2data/venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2719\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2716\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2717\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2719\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   2720\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2721\u001b[0m     config,\n\u001b[1;32m   2722\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   2723\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2724\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   2725\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   2726\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during,\n\u001b[1;32m   2727\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2729\u001b[0m ):\n\u001b[1;32m   2730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2731\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2732\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2733\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (ints \u001b[38;5;241m:=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mget(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2734\u001b[0m         ):\n",
      "File \u001b[0;32m~/projects/netflix_talk2data/venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2456\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2448\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[1;32m   2449\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   2450\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2454\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mGRAPH_RECURSION_LIMIT,\n\u001b[1;32m   2455\u001b[0m     )\n\u001b[0;32m-> 2456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[1;32m   2457\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   2458\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "# src/main.py\n",
    "\n",
    "from graph.workflow import build_graph\n",
    "\n",
    "def run_once(user_query: str):\n",
    "    \"\"\"\n",
    "    Build the graph, run it end‚Äëto‚Äëend, and return the final AgentState.\n",
    "    \"\"\"\n",
    "    # 1) Compile the workflow\n",
    "    graph = build_graph()\n",
    "\n",
    "    # 2) Prepare the initial state for LangGraph\n",
    "    #    All nodes share this same AgentState schema.\n",
    "    initial_state = {\n",
    "        \"messages\": [ {\"role\": \"user\", \"content\": user_query} ]\n",
    "    }\n",
    "\n",
    "    # 3) Invoke the graph synchronously (follows supervisor‚Üíenhancer‚Üísearch‚ÜíEND)\n",
    "    final_state = graph.invoke(initial_state)\n",
    "\n",
    "    # 4) Inspect or return the final state\n",
    "    return final_state\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Find 5 B2B SaaS startups in India \"\n",
    "    result = run_once(query)\n",
    "\n",
    "    print(\"=== Final State ===\")\n",
    "    print(f\"Enhanced Query   : {result.get('enhanced_query')}\")\n",
    "    print(f\"Filters          : {result.get('filters')}\")\n",
    "    print(f\"Top‚ÄëK (k)        : {result.get('k')}\")\n",
    "    print(f\"Results          : {result.get('retrieved_results')}\")\n",
    "    print(f\"Trace Actions    : {result.get('actions')}\")\n",
    "    print(f\"Trace Observations: {result.get('observations')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
