{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92711e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SRC path added: /home/prashant-agrawal/projects/netflix_talk2data/src\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "try:\n",
    "    # âœ… Running from a Python script (.py file)\n",
    "    base_path = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\", \"..\"))\n",
    "except NameError:\n",
    "    # âœ… Running from a Jupyter notebook (__file__ is not defined)\n",
    "    base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "\n",
    "SRC_PATH = os.path.join(base_path)\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "    print(f\"âœ… SRC path added: {SRC_PATH}\")\n",
    "else:\n",
    "    print(f\"ğŸ” SRC path already in sys.path: {SRC_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6b4ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Collection Name: indian_startups\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Import your utility loaders\n",
    "from utils.qdrant_client_loader import get_qdrant_collection_name\n",
    "\n",
    "\n",
    "# ğŸ“‚ Define paths and configurations\n",
    "\n",
    "COLLECTION_NAME = get_qdrant_collection_name()\n",
    "\n",
    "print(f\"ğŸ“Œ Collection Name: {COLLECTION_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276d9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utility: Normalization ---\n",
    "def normalize_field_name(field: str) -> str:\n",
    "    return (\n",
    "        field.strip().lower()\n",
    "        .replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        .replace(\"/\", \"_\")\n",
    "    )\n",
    "\n",
    "def normalize_field_value(value) -> str:\n",
    "    return str(value).strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e086e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/tools/qdrant_tool.py\n",
    "\n",
    "import re\n",
    "from typing import List, Dict, Any, Union\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import FieldCondition, MatchValue, Range, Filter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "class QdrantSearchTool:\n",
    "    \"\"\"\n",
    "    Tool for performing hybrid semantic + metadata searches against a Qdrant collection.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        host: str,\n",
    "        port: int,\n",
    "        collection_name: str,\n",
    "        embedding_model: OpenAIEmbeddings,\n",
    "    ):\n",
    "        self.client = QdrantClient(host=host, port=port)\n",
    "        self.collection = collection_name\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_field_name(field: str) -> str:\n",
    "        f = field.strip().lower()\n",
    "        f = re.sub(r\"[ ()/]\", \"_\", f)\n",
    "        return re.sub(r\"[^a-z0-9_]\", \"\", f)\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_field_value(value: Any) -> str:\n",
    "        return str(value).strip().lower()\n",
    "\n",
    "    def _build_filter(self, filters: Dict[str, Union[str, int, float, Dict[str, Any]]]) -> Filter:\n",
    "        \"\"\"\n",
    "        Convert a user-provided dict of filters into a Qdrant Filter object.\n",
    "        Supports:\n",
    "          - exact match: {\"state\": \"delhi\"}\n",
    "          - range match: {\"year_founded\": {\"gte\": 2000, \"lte\": 2010}}\n",
    "        \"\"\"\n",
    "        conditions = []\n",
    "        for raw_field, cond in filters.items():\n",
    "            key = self._normalize_field_name(raw_field)\n",
    "\n",
    "            if isinstance(cond, dict) and (\"gte\" in cond or \"lte\" in cond):\n",
    "                conditions.append(\n",
    "                    FieldCondition(\n",
    "                        key=key,\n",
    "                        range=Range(gte=cond.get(\"gte\"), lte=cond.get(\"lte\")),\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                val = self._normalize_field_value(cond)\n",
    "                conditions.append(\n",
    "                    FieldCondition(key=key, match=MatchValue(value=val))\n",
    "                )\n",
    "\n",
    "        return Filter(must=conditions)\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        query: str,\n",
    "        filters: Dict[str, Union[str, int, float, Dict[str, Any]]] = None,\n",
    "        k: int = 5,\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Perform a similarity search with optional metadata filtering.\n",
    "        Returns a list of dicts: { \"id\", \"score\", \"payload\" }.\n",
    "        \"\"\"\n",
    "        # 1. Embed the query\n",
    "        vector = self.embedding_model.embed_query(query)\n",
    "\n",
    "        # 2. Build Qdrant filter if provided\n",
    "        q_filter = self._build_filter(filters) if filters else None\n",
    "\n",
    "        # 3. Execute search\n",
    "        results = self.client.search(\n",
    "            collection_name=self.collection,\n",
    "            query_vector=vector,\n",
    "            query_filter=q_filter,\n",
    "            limit=k,\n",
    "            with_payload=True,\n",
    "        )\n",
    "\n",
    "        # 4. Format output\n",
    "        output = []\n",
    "        for pt in results:\n",
    "            output.append({\n",
    "                \"id\": pt.id,\n",
    "                \"score\": pt.score,\n",
    "                \"payload\": pt.payload,\n",
    "            })\n",
    "        return output\n",
    "\n",
    "# 4ï¸âƒ£ Instantiate once\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "qdrant_search_tool = QdrantSearchTool(\n",
    "    host=\"localhost\",\n",
    "    port=6333,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_model=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac2049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wrapper for LangChain agent compatibility\n",
    "def wrapped_qdrant_search(inputs: dict) -> list:\n",
    "    query = inputs.get(\"query\", \"\")\n",
    "    filters = inputs.get(\"filters\", None)\n",
    "    k = inputs.get(\"k\", 5)\n",
    "    print(f\"\\n[DEBUG] Query: {query}\")\n",
    "    print(f\"[DEBUG] Filters: {filters}\")\n",
    "    print(f\"[DEBUG] Top K: {k}\")\n",
    "    try:\n",
    "        results = qdrant_search_tool.search(query=query, filters=filters, k=k)\n",
    "        print(f\"[DEBUG] Raw results: {results}\")\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Qdrant search failed: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "190b136a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Test: pure semantic (no filters)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7014/792566242.py:80: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " â€¢ [0.7726] boat\n",
      " â€¢ [0.7726] None\n",
      " â€¢ [0.7726] None\n",
      "\n",
      "ğŸ” Test: metadata-only filter state=delhi\n",
      " â€¢ cred (state=delhi)\n",
      " â€¢ curefit (state=delhi)\n",
      " â€¢ tork motors (state=delhi)\n",
      " â€¢ lenskart (state=delhi)\n",
      " â€¢ yulu (state=delhi)\n",
      "\n",
      "ğŸ” Test: range filter year_founded in [2000,2010]\n"
     ]
    }
   ],
   "source": [
    "# 5ï¸âƒ£ Test functions\n",
    "def test_semantic():\n",
    "    print(\"ğŸ” Test: pure semantic (no filters)\")\n",
    "    for r in qdrant_search_tool.search(query=\"emerging fintech startups\", k=3):\n",
    "        print(f\" â€¢ [{r['score']:.4f}] {r['payload'].get('company_name')}\")\n",
    "\n",
    "def test_metadata():\n",
    "    print(\"ğŸ” Test: metadata-only filter state=delhi\")\n",
    "    for r in qdrant_search_tool.search(query=\"\", filters={\"state\": \"delhi\"}, k=5):\n",
    "        print(f\" â€¢ {r['payload']['company_name']} (state={r['payload']['state']})\")\n",
    "\n",
    "def test_range():\n",
    "    print(\"ğŸ” Test: range filter year_founded in [2000,2010]\")\n",
    "    for r in qdrant_search_tool.search(\n",
    "        query=\"\",\n",
    "        filters={\"year_founded\": {\"gte\": 2000, \"lte\": 2010}},\n",
    "        k=5\n",
    "    ):\n",
    "        print(f\" â€¢ {r['payload']['company_name']} (founded={r['payload']['year_founded']})\")\n",
    "\n",
    "# 6ï¸âƒ£ Run all tests\n",
    "test_semantic()\n",
    "print()\n",
    "test_metadata()\n",
    "print()\n",
    "test_range()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
