{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92711e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prashant-agrawal/projects/netflix_talk2data/src\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "SRC_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\",\"..\"))\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "print(SRC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd6b4ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Base Dir: /home/prashant-agrawal/projects/netflix_talk2data/src\n",
      "üìå CSV Path: /home/prashant-agrawal/projects/netflix_talk2data/src/Data/Enriched_Indian_Startup_Dataset.csv\n",
      "üìå Qdrant Local Path: /home/prashant-agrawal/projects/netflix_talk2data/src/database/qdrant_store_local_db/collection\n",
      "üìå Collection Name: indian_startups\n",
      "üìå Schema Path: /home/prashant-agrawal/projects/netflix_talk2data/src/schema/payload_schema.json\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Import your utility loaders\n",
    "from utils.qdrant_client_loader import get_qdrant_collection_name\n",
    "from utils.path_config import get_base_dir, get_data_path, get_qdrant_store_path, get_schema_path\n",
    "\n",
    "# %% üìÅ Paths\n",
    "BASE_DIR = get_base_dir()\n",
    "DATA_PATH = get_data_path()\n",
    "SCHEMA_OUTPUT_PATH = get_schema_path()\n",
    "qdrant_store_path = get_qdrant_store_path()\n",
    "COLLECTION_NAME = get_qdrant_collection_name()\n",
    "\n",
    "print(f\"üìå Base Dir: {BASE_DIR}\")\n",
    "print(f\"üìå CSV Path: {DATA_PATH}\")\n",
    "print(f\"üìå Qdrant Local Path: {qdrant_store_path}\")\n",
    "print(f\"üìå Collection Name: {COLLECTION_NAME}\")\n",
    "print(f\"üìå Schema Path: {SCHEMA_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "276d9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utility: Normalization ---\n",
    "def normalize_field_name(field: str) -> str:\n",
    "    return (\n",
    "        field.strip().lower()\n",
    "        .replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        .replace(\"/\", \"_\")\n",
    "    )\n",
    "\n",
    "def normalize_field_value(value) -> str:\n",
    "    return str(value).strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e086e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/tools/qdrant_tool.py\n",
    "\n",
    "import re\n",
    "from typing import List, Dict, Any, Union\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import FieldCondition, MatchValue, Range, Filter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "class QdrantSearchTool:\n",
    "    \"\"\"\n",
    "    Tool for performing hybrid semantic + metadata searches against a Qdrant collection.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        host: str,\n",
    "        port: int,\n",
    "        collection_name: str,\n",
    "        embedding_model: OpenAIEmbeddings,\n",
    "    ):\n",
    "        self.client = QdrantClient(host=host, port=port)\n",
    "        self.collection = collection_name\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_field_name(field: str) -> str:\n",
    "        f = field.strip().lower()\n",
    "        f = re.sub(r\"[ ()/]\", \"_\", f)\n",
    "        return re.sub(r\"[^a-z0-9_]\", \"\", f)\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_field_value(value: Any) -> str:\n",
    "        return str(value).strip().lower()\n",
    "\n",
    "    def _build_filter(self, filters: Dict[str, Union[str, int, float, Dict[str, Any]]]) -> Filter:\n",
    "        \"\"\"\n",
    "        Convert a user-provided dict of filters into a Qdrant Filter object.\n",
    "        Supports:\n",
    "          - exact match: {\"state\": \"delhi\"}\n",
    "          - range match: {\"year_founded\": {\"gte\": 2000, \"lte\": 2010}}\n",
    "        \"\"\"\n",
    "        conditions = []\n",
    "        for raw_field, cond in filters.items():\n",
    "            key = self._normalize_field_name(raw_field)\n",
    "\n",
    "            if isinstance(cond, dict) and (\"gte\" in cond or \"lte\" in cond):\n",
    "                conditions.append(\n",
    "                    FieldCondition(\n",
    "                        key=key,\n",
    "                        range=Range(gte=cond.get(\"gte\"), lte=cond.get(\"lte\")),\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                val = self._normalize_field_value(cond)\n",
    "                conditions.append(\n",
    "                    FieldCondition(key=key, match=MatchValue(value=val))\n",
    "                )\n",
    "\n",
    "        return Filter(must=conditions)\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        query: str,\n",
    "        filters: Dict[str, Union[str, int, float, Dict[str, Any]]] = None,\n",
    "        k: int = 5,\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Perform a similarity search with optional metadata filtering.\n",
    "        Returns a list of dicts: { \"id\", \"score\", \"payload\" }.\n",
    "        \"\"\"\n",
    "        # 1. Embed the query\n",
    "        vector = self.embedding_model.embed_query(query)\n",
    "\n",
    "        # 2. Build Qdrant filter if provided\n",
    "        q_filter = self._build_filter(filters) if filters else None\n",
    "\n",
    "        # 3. Execute search\n",
    "        results = self.client.search(\n",
    "            collection_name=self.collection,\n",
    "            query_vector=vector,\n",
    "            query_filter=q_filter,\n",
    "            limit=k,\n",
    "            with_payload=True,\n",
    "        )\n",
    "\n",
    "        # 4. Format output\n",
    "        output = []\n",
    "        for pt in results:\n",
    "            output.append({\n",
    "                \"id\": pt.id,\n",
    "                \"score\": pt.score,\n",
    "                \"payload\": pt.payload,\n",
    "            })\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "190b136a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Test: pure semantic (no filters)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83837/1317750719.py:80: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚Ä¢ [0.7726] boat\n",
      " ‚Ä¢ [0.7726] None\n",
      " ‚Ä¢ [0.7726] None\n",
      "\n",
      "üîç Test: metadata-only filter state=delhi\n",
      " ‚Ä¢ cred (state=delhi)\n",
      " ‚Ä¢ curefit (state=delhi)\n",
      " ‚Ä¢ tork motors (state=delhi)\n",
      " ‚Ä¢ lenskart (state=delhi)\n",
      " ‚Ä¢ yulu (state=delhi)\n",
      "\n",
      "üîç Test: range filter year_founded in [2000,2010]\n"
     ]
    }
   ],
   "source": [
    "# 4Ô∏è‚É£ Instantiate once\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "tool = QdrantSearchTool(\n",
    "    host=\"localhost\",\n",
    "    port=6333,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_model=embedding_model\n",
    ")\n",
    "\n",
    "# 5Ô∏è‚É£ Test functions\n",
    "def test_semantic():\n",
    "    print(\"üîç Test: pure semantic (no filters)\")\n",
    "    for r in tool.search(query=\"emerging fintech startups\", k=3):\n",
    "        print(f\" ‚Ä¢ [{r['score']:.4f}] {r['payload'].get('company_name')}\")\n",
    "\n",
    "def test_metadata():\n",
    "    print(\"üîç Test: metadata-only filter state=delhi\")\n",
    "    for r in tool.search(query=\"\", filters={\"state\": \"delhi\"}, k=5):\n",
    "        print(f\" ‚Ä¢ {r['payload']['company_name']} (state={r['payload']['state']})\")\n",
    "\n",
    "def test_range():\n",
    "    print(\"üîç Test: range filter year_founded in [2000,2010]\")\n",
    "    for r in tool.search(\n",
    "        query=\"\",\n",
    "        filters={\"year_founded\": {\"gte\": 2000, \"lte\": 2010}},\n",
    "        k=5\n",
    "    ):\n",
    "        print(f\" ‚Ä¢ {r['payload']['company_name']} (founded={r['payload']['year_founded']})\")\n",
    "\n",
    "# 6Ô∏è‚É£ Run all tests\n",
    "test_semantic()\n",
    "print()\n",
    "test_metadata()\n",
    "print()\n",
    "test_range()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
