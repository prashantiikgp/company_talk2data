{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0444b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.3.61-py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m438.3/438.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tenacity!=8.4.0,<10.0.0,>=8.1.0\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from langchain-core) (6.0.2)\n",
      "Collecting pydantic>=2.7.4\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m444.2/444.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging<25,>=23.2\n",
      "  Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langsmith<0.4,>=0.1.126\n",
      "  Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m360.3/360.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.7 in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from langchain-core) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx<1,>=0.23.0 in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (0.28.1)\n",
      "Collecting zstandard<0.24.0,>=0.23.0\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (2.32.3)\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Downloading orjson-3.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspection>=0.4.0\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: anyio in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (4.9.0)\n",
      "Requirement already satisfied: idna in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: certifi in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (2025.4.26)\n",
      "Requirement already satisfied: h11>=0.16 in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core) (3.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/prashant-agrawal/projects/netflix_talk2data/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (1.3.0)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, pydantic-core, packaging, orjson, jsonpatch, annotated-types, requests-toolbelt, pydantic, langsmith, langchain-core\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed annotated-types-0.7.0 jsonpatch-1.33 langchain-core-0.3.61 langsmith-0.3.42 orjson-3.10.18 packaging-24.2 pydantic-2.11.5 pydantic-core-2.33.2 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspection-0.4.1 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the dependencies\n",
    "%pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec12974",
   "metadata": {},
   "outputs": [],
   "source": [
    "##--Keyword Extractor--##\n",
    "# This script extracts keywords from a given query string and maps them to specific fields.\n",
    "# It uses a predefined dictionary of filterable fields and their associated keywords.\n",
    "# The script defines a function `keyword_extractor_fn` that takes a query string as input.\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "from typing import Dict, Any\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "FILTERABLE_FIELDS: Dict[str, list] = {\n",
    "    # ğŸŒ Location\n",
    "    \"headquarters_city\": [\n",
    "        \"city\", \"headquarters\", \"based in\", \"location\", \"bengaluru\", \"bangalore\",\n",
    "        \"mumbai\", \"delhi\", \"chennai\", \"kolkata\", \"hyderabad\", \"jaipur\", \"ahmedabad\"\n",
    "    ],\n",
    "    \"state\": [\n",
    "        \"state\", \"region\", \"area\", \"in maharashtra\", \"in karnataka\", \"in gujarat\"\n",
    "    ],\n",
    "\n",
    "    # ğŸ­ Industry + Category (merged with classifier synonyms)\n",
    "    \"industry_sector\": [\n",
    "        \"industry\", \"sector\", \"domain\", \"vertical\",\n",
    "        \"saas\", \"software-as-a-service\", \"cloud software\",\n",
    "        \"b2b\", \"business to business\",\n",
    "        \"b2c\", \"business to consumer\",\n",
    "        \"d2c\", \"direct to consumer\",\n",
    "        \"fintech\", \"financial technology\", \"digital bank\", \"payments\",\n",
    "        \"ecommerce\", \"online store\", \"digital retail\",\n",
    "        \"logistics\", \"supply chain\", \"delivery\", \"transport\",\n",
    "        \"healthtech\", \"digital health\", \"telemedicine\",\n",
    "        \"edtech\", \"education technology\", \"online learning\",\n",
    "        \"agritech\", \"agriculture technology\", \"farming tech\",\n",
    "        \"cleantech\", \"climate tech\", \"sustainability\"\n",
    "    ],\n",
    "\n",
    "    # ğŸ’° Financial\n",
    "    \"total_funding_raised_inr\": [\n",
    "        \"funding\", \"raised\", \"capital\", \"total raised\", \"total investment\", \"â‚¹\", \"cr\",\n",
    "        \"crore\", \"million\", \"billion\", \"over â‚¹\", \"less than â‚¹\", \"above â‚¹\", \"under â‚¹\"\n",
    "    ],\n",
    "    \"valuation_estimate_if_available\": [\n",
    "        \"valuation\", \"worth\", \"company valuation\", \"valued at\", \"estimated worth\",\n",
    "        \"â‚¹ valuation\", \"how much is it worth\"\n",
    "    ],\n",
    "    \"revenue_estimate_annual\": [\n",
    "        \"revenue\", \"income\", \"turnover\", \"sales\", \"â‚¹ revenue\", \"annual revenue\",\n",
    "        \"earning\"\n",
    "    ],\n",
    "    \"number_of_funding_rounds\": [\n",
    "        \"funding rounds\", \"number of rounds\", \"how many times\", \"rounds raised\"\n",
    "    ],\n",
    "    \"latest_funding_round_type\": [\n",
    "        \"round type\", \"series a\", \"series b\", \"seed\", \"pre-seed\", \"bridge round\",\n",
    "        \"angel\", \"growth round\", \"venture round\"\n",
    "    ],\n",
    "    \"latest_funding_date\": [\n",
    "        \"funding date\", \"latest funding\", \"last raised\", \"when did it raise\"\n",
    "    ],\n",
    "\n",
    "    # ğŸ‘¥ People\n",
    "    \"founders\": [\n",
    "        \"founders\", \"co-founders\", \"started by\", \"founded by\", \"entrepreneurs\",\n",
    "        \"startup founders\", \"iit\", \"iim\", \"alumni\", \"serial entrepreneur\"\n",
    "    ],\n",
    "    \"board_members__advisors\": [\n",
    "        \"board\", \"advisors\", \"board members\", \"mentors\", \"director\"\n",
    "    ],\n",
    "\n",
    "    # ğŸ§‘â€ğŸ’¼ Hiring\n",
    "    \"hiring_status\": [\n",
    "        \"hiring\", \"actively hiring\", \"hiring freeze\", \"currently hiring\", \"not hiring\"\n",
    "    ],\n",
    "    \"popular_roles_open\": [\n",
    "        \"roles\", \"job openings\", \"positions\", \"jobs\", \"vacancies\", \"engineers\",\n",
    "        \"product managers\", \"sales roles\", \"open roles\"\n",
    "    ],\n",
    "\n",
    "    # ğŸ“¦ Products / Tech\n",
    "    \"primary_products__services\": [\n",
    "        \"products\", \"services\", \"offers\", \"tools\", \"solutions\", \"platform\",\n",
    "        \"mobile app\", \"AI tools\", \"API\", \"product line\", \"dashboard\", \"crm\", \"analytics\"\n",
    "    ],\n",
    "    \"product_categories\": [\n",
    "        \"category\", \"type of product\", \"business model\", \"B2B\", \"B2C\", \"D2C\", \"SMB\",\n",
    "        \"enterprise\", \"consumer\", \"retail\", \"wholesale\"\n",
    "    ],\n",
    "    \"tech_stack\": [\n",
    "        \"technology\", \"tech stack\", \"framework\", \"platform\", \"built on\", \"python\",\n",
    "        \"node.js\", \"aws\", \"gcp\", \"react\", \"java\", \"spring boot\", \"azure\"\n",
    "    ],\n",
    "    \"integrations__apis_offered\": [\n",
    "        \"integrates with\", \"API\", \"integrations\", \"third-party tools\", \"razorpay\",\n",
    "        \"tally\", \"zoho\", \"crm\"\n",
    "    ],\n",
    "\n",
    "    # ğŸ“£ Market Presence\n",
    "    \"major_customers__logos\": [\n",
    "        \"clients\", \"customers\", \"buyers\", \"logos\", \"key accounts\", \"target accounts\",\n",
    "        \"enterprise clients\", \"big customers\"\n",
    "    ],\n",
    "    \"competitors\": [\n",
    "        \"competitors\", \"similar to\", \"like\", \"versus\", \"against\", \"same space\",\n",
    "        \"competing with\", \"similar company\"\n",
    "    ],\n",
    "\n",
    "    # ğŸ“† Time & Growth\n",
    "    \"year_founded\": [\n",
    "        \"founded\", \"established\", \"founded in\", \"year of founding\", \"launched\",\n",
    "        \"started in\", \"beginning\"\n",
    "    ],\n",
    "    \"employee_growth_yoy_\": [\n",
    "        \"employee growth\", \"hiring trend\", \"growth rate\", \"yoy growth\", \"team growth\"\n",
    "    ],\n",
    "    \"number_of_employees_current\": [\n",
    "        \"employees\", \"team size\", \"staff\", \"how many people\", \"employee count\",\n",
    "        \"current employees\"\n",
    "    ],\n",
    "    \"number_of_employees_estimate_range\": [\n",
    "        \"employee range\", \"size of team\", \"headcount range\"\n",
    "    ],\n",
    "\n",
    "    # ğŸ†• Named Entities & Tags\n",
    "    \"company_name\": [\"flipkart\", \"paytm\", \"zomato\", \"cred\", \"byjus\", \"zoho\", \"freshworks\"],\n",
    "    \"investors\": [\"sequoia\", \"accel\", \"tiger global\", \"blume ventures\", \"softbank\", \"matrix partners\"],\n",
    "    \"labels\": [\"unicorn\", \"soonicorn\", \"top startup\", \"high growth\", \"bootstrap\", \"market leader\"]\n",
    "}\n",
    "\n",
    "\n",
    "def keyword_extractor_fn(query: str) -> Dict[str, str]:\n",
    "    query_lower = query.lower()\n",
    "    result: Dict[str, Any] = {}\n",
    "\n",
    "    for field, keywords in FILTERABLE_FIELDS.items():\n",
    "        matched = [kw for kw in keywords if kw in query_lower]\n",
    "        if matched:\n",
    "            result[field] = list(set(matched))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37ccbb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'headquarters_city': ['delhi'], 'total_funding_raised_inr': ['over â‚¹', 'cr', 'raised', 'â‚¹', 'crore'], 'revenue_estimate_annual': ['revenue'], 'hiring_status': ['hiring'], 'popular_roles_open': ['engineers']}\n"
     ]
    }
   ],
   "source": [
    "# âœ… Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"\"\"\n",
    "    \n",
    "    \"Show me companies headquartered in Delhi with revenue over â‚¹50 crore, hiring engineers, and having raised â‚¹100 crore.\"\n",
    "\n",
    "    \"\"\"\n",
    "    print(keyword_extractor_fn(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
