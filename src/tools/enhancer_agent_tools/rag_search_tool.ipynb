{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d10a2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prashant-agrawal/projects/netflix_talk2data/src\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "SRC_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "print(SRC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cd7d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant store path: /home/prashant-agrawal/projects/netflix_talk2data/src/database/qdrant_store_local_db/collection\n",
      "Data path: /home/prashant-agrawal/projects/netflix_talk2data/src/Data/Enriched_Indian_Startup_Dataset.csv\n",
      "Schema path: /home/prashant-agrawal/projects/netflix_talk2data/src/schema/payload_schema.json\n",
      "Vector store path: /home/prashant-agrawal/projects/netflix_talk2data/src/database/vector_store/faiss_full_row_index\n",
      "Base directory: /home/prashant-agrawal/projects/netflix_talk2data/src\n"
     ]
    }
   ],
   "source": [
    "# rag_search_tool.py\n",
    "\n",
    "import os\n",
    "from typing import List, Optional, Dict\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from typing import List, Optional, Dict, Any\n",
    "\n",
    "from utils.path_config import get_base_dir ,get_vector_store_path\n",
    "\n",
    "# Path setup\n",
    "BASE_DIR = get_base_dir()\n",
    "\n",
    "vector_path = get_vector_store_path()\n",
    "\n",
    "\n",
    "print(f\"Vector store path: {vector_path}\")\n",
    "print(f\"Base directory: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea99ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Input Schema\n",
    "from typing import Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RagSearchInput(BaseModel):\n",
    "    query: str = Field(..., description=\"User's semantic query\")\n",
    "    #filters: Optional[Dict[str, Any]] = Field(default=None, description=\"Structured filters extracted\")\n",
    "    k: Optional[int] = Field(default=5, description=\"Number of results to return\")\n",
    "\n",
    "\n",
    "# ‚úÖ Output Schema\n",
    "class RagSearchResult(BaseModel):\n",
    "    results: List[str]\n",
    "    message: str = \"\"\n",
    "\n",
    "    def dict(self):\n",
    "        return {\n",
    "            \"results\": self.results,\n",
    "            \"message\": self.message\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d114d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Caching FAISS index\n",
    "_vector_cache = {}\n",
    "\n",
    "def load_vector_store(path: str = vector_path) -> FAISS:\n",
    "    if path in _vector_cache:\n",
    "        vectorstore = _vector_cache[path]\n",
    "        return vectorstore\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        return RagSearchResult(results=[], message=\"Vector store not found.\").dict()\n",
    "\n",
    "# Load OpenAI embeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Load the FAISS index\n",
    "    vector_store = FAISS.load_local(\n",
    "        path, \n",
    "        embeddings, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    _vector_cache[path] = vector_store\n",
    "    return vector_store\n",
    "\n",
    "  \n",
    "print(\"FAISS index loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2514c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_search_fn(query: str, k: int = 5) -> Dict:\n",
    "    print(f\"[RAG Tool] Query: {query}\")\n",
    "    print(f\"[RAG Tool] Top K: {k}\")\n",
    "\n",
    "    if vector_path in _vector_cache:\n",
    "        print(f\"[RAG Tool] Using cached vector store\")\n",
    "        vectorstore = _vector_cache[vector_path]\n",
    "    else:\n",
    "        if not os.path.exists(vector_path):\n",
    "            print(f\"[ERROR] FAISS directory not found at {vector_path}\")\n",
    "            return RagSearchResult(results=[], message=\"Vector store not found.\").dict()\n",
    "\n",
    "        print(f\"[RAG Tool] Loading vector store from disk...\")\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        try:\n",
    "            vectorstore = FAISS.load_local(\n",
    "                vector_path,\n",
    "                embeddings,\n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            _vector_cache[vector_path] = vectorstore\n",
    "            print(\"[RAG Tool] FAISS vector store loaded.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to load FAISS: {e}\")\n",
    "            return RagSearchResult(results=[], message=\"Error loading vector store\").dict()\n",
    "\n",
    "    try:\n",
    "        raw_docs = vectorstore.similarity_search(query=query, k=k)\n",
    "        print(f\"[RAG Tool] Retrieved {len(raw_docs)} documents.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Similarity search failed: {e}\")\n",
    "        return RagSearchResult(results=[], message=\"Vector search failed\").dict()\n",
    "\n",
    "    if not raw_docs:\n",
    "        return RagSearchResult(results=[], message=\"No results found.\").dict()\n",
    "\n",
    "    return RagSearchResult(\n",
    "        results=[doc.page_content for doc in raw_docs],\n",
    "        message=f\"Top {len(raw_docs)} documents returned.\"\n",
    "    ).dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ef2bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAG Tool] Query: Find B2C and e-commerce startups in the SaaS and logistics space\n",
      "[RAG Tool] Top K: 5\n",
      "[RAG Tool] Loading vector store from disk...\n",
      "[ERROR] Failed to load FAISS: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).\n",
      "‚ùå No valid documents found.\n",
      "‚ÑπÔ∏è Full Output: {'results': [], 'message': 'Error loading vector store'}\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Find B2C and e-commerce startups in the SaaS and logistics space\"\n",
    "    example_filters = {\n",
    "    \"industry_sector\": [\"SaaS\", \"Logistics\"],\n",
    "    \"product_categories\": [\"B2B\", \"B2C\", \"E-commerce\"]\n",
    "}\n",
    "    result = rag_search_fn(query=query, k=5)\n",
    "    \n",
    "\n",
    "    if result[\"results\"]:\n",
    "        print(f\"‚úÖ Found {len(result['results'])} documents.\")\n",
    "        for doc in result[\"results\"]:\n",
    "            print(f\"üìÑ Content: {doc[:100]}...\")\n",
    "    else:\n",
    "        print(\"‚ùå No valid documents found.\")\n",
    "\n",
    "    print(\"‚ÑπÔ∏è Full Output:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
