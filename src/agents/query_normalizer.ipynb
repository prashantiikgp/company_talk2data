{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfed16f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e8d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install symspellpy phonetics rapidfuzz spacy openai fuzzy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddcf8149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SRC path added: /home/prashant-agrawal/projects/company_talk2data/src\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import sys, os\n",
    "try:\n",
    "    # âœ… Running from a Python script (.py file)\n",
    "    TOOLS_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\",))\n",
    "except NameError:\n",
    "    # âœ… Running from a Jupyter notebook (__file__ is not defined)\n",
    "    TOOLS_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "SRC_PATH = os.path.join(TOOLS_PATH)\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "    print(f\"âœ… SRC path added: {SRC_PATH}\")\n",
    "else:\n",
    "    print(f\"ðŸ” SRC path already in sys.path: {SRC_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a743a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "from rapidfuzz import process, fuzz\n",
    "from phonetics import dmetaphone\n",
    "from typing import List, Dict\n",
    "\n",
    "from utils.path_config import get_dictionary_path\n",
    "\n",
    "# %% ðŸ“ Paths\n",
    "Dict_PATH = get_dictionary_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Loading SymSpell dictionary from: /home/prashant-agrawal/projects/company_talk2data/src/Data/frequency_dictionary_en_82_765.txt\n",
      "âœ… Custom terms loaded into SymSpell: 99\n",
      "Loaded custom words: ['\\ufeffthe', 'of', 'and', 'to', 'a', 'in', 'for', 'is', 'on', 'that']\n"
     ]
    }
   ],
   "source": [
    "# Custom domain vocabulary (your FILTERABLE_FIELDS)\n",
    "#FILTERABLE_FIELDS = {   \n",
    "#    \"fintech\", \"saas\", \"healthtech\", \"crm\", \"b2b\", \"b2c\", \"d2c\",\n",
    "#    \"cred\", \"zoho\", \"flipkart\", \"founder\", \"funding\", \"revenue\",\n",
    "#    \"valuation\", \"series a\", \"seed\", \"bangalore\", \"bengaluru\", \"mumbai\", \"hiring\",\n",
    "#    \"employees\", \"team\", \"growth\", \"unicorn\", \"bootstrap\", \"zoho\"\n",
    "#}\n",
    "\n",
    "# âœ… Extensive filterable fields (flattened set for priority)\n",
    "FILTERABLE_FIELDS = set([\n",
    "    # ðŸŒ Locations\n",
    "    \"bengaluru\", \"bangalore\", \"mumbai\", \"delhi\", \"noida\", \"gurgaon\", \"hyderabad\", \"chennai\", \"pune\", \"kolkata\",\n",
    "    \"india\", \"remote\", \"usa\", \"new york\", \"london\", \"singapore\", \"dubai\",\n",
    "\n",
    "    # ðŸ­ Industries\n",
    "    \"fintech\", \"saas\", \"healthtech\", \"edtech\", \"agritech\", \"cleantech\", \"ecommerce\", \"logistics\", \"traveltech\",\n",
    "    \"retailtech\", \"cybersecurity\", \"medtech\", \"insurtech\", \"govtech\", \"spacetech\", \"web3\", \"blockchain\", \"crm\",\n",
    "\n",
    "    # ðŸ“¦ Tech & Products\n",
    "    \"mobile app\", \"web app\", \"api\", \"platform\", \"software\", \"cloud\", \"dashboard\", \"plugin\", \"extension\", \"erp\",\n",
    "    \"analytics\", \"microservices\", \"serverless\", \"paas\", \"saas\", \"open source\",\n",
    "\n",
    "    # ðŸ‘¥ People\n",
    "    \"founder\", \"cofounder\", \"ceo\", \"cto\", \"cxo\", \"team\", \"employees\", \"staff\", \"leadership\",\n",
    "\n",
    "    # ðŸ’¼ Company Activity\n",
    "    \"hiring\", \"layoffs\", \"ipo\", \"acquisition\", \"merger\", \"pivot\", \"shutdown\", \"exit\",\n",
    "\n",
    "    # ðŸ’° Finance\n",
    "    \"funding\", \"valuation\", \"revenue\", \"profit\", \"loss\", \"ebitda\", \"runway\", \"investors\", \"bootstrap\", \"unicorn\",\n",
    "    \"series a\", \"series b\", \"seed\", \"angel\", \"growth\",\n",
    "\n",
    "    # ðŸ”– Tags\n",
    "    \"high growth\", \"market leader\", \"top startup\", \"soonicorn\", \"early stage\", \"late stage\", \"yc backed\",\n",
    "\n",
    "    # ðŸ“ˆ Metrics\n",
    "    \"users\", \"downloads\", \"retention\", \"engagement\", \"mrr\", \"arr\", \"ltv\", \"cac\", \"churn\", \"arpu\"\n",
    "])\n",
    "\n",
    "\n",
    "# âœ… Initialize SymSpell\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "\n",
    "       \n",
    "# âœ… Load main dictionary\n",
    "dict_path = os.path.join(Dict_PATH())\n",
    "print(f\"ðŸ” Loading SymSpell dictionary from: {dict_path}\")\n",
    "\n",
    "# Check if the dictionary file exists\n",
    "loaded = sym_spell.load_dictionary(dict_path, term_index=0, count_index=1)\n",
    "if not loaded:\n",
    "    raise RuntimeError(\"âŒ Could not load main dictionary\")\n",
    "\n",
    "for word in FILTERABLE_FIELDS:\n",
    "    word_clean = word.lower().strip()\n",
    "    if word_clean and word_clean not in sym_spell.words:\n",
    "        sym_spell.create_dictionary_entry(word_clean, 99999)\n",
    "\n",
    "print(\"âœ… Custom terms loaded into SymSpell:\", len(FILTERABLE_FIELDS))\n",
    "\n",
    "# Verify loaded dictionary (optional)\n",
    "print(\"Loaded custom words:\", list(sym_spell.words)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d9d9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SymSpell Corrected Query: healthtech did of companies in india\n"
     ]
    }
   ],
   "source": [
    "def symspell_correct(query: str) -> str:\n",
    "    suggestion = sym_spell.lookup_compound(query, max_edit_distance=2)\n",
    "    return suggestion[0].term if suggestion else query\n",
    "\n",
    "# Example usage\n",
    "query = \"healtytech dcd2f compnies in oindia\"\n",
    "corrected_query = symspell_correct(query)\n",
    "print(\"âœ… SymSpell Corrected Query:\", corrected_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63df7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install fuzzy\n",
    "from fuzzy import DMetaphone\n",
    "\n",
    "dmetaphone = DMetaphone()\n",
    "\n",
    "def build_phonetic_dict(fields: set) -> dict:\n",
    "    phonetic_dict = {}\n",
    "    for word in fields:\n",
    "        ascii_word = ''.join([c for c in word.lower() if ord(c) < 128])\n",
    "        codes = dmetaphone(ascii_word)\n",
    "        code = codes[0] if codes and codes[0] else None\n",
    "        if code and code not in phonetic_dict:\n",
    "            phonetic_dict[code] = ascii_word\n",
    "    return phonetic_dict\n",
    "\n",
    "phonetic_dict = build_phonetic_dict(FILTERABLE_FIELDS)\n",
    "\n",
    "def phonetic_correction(query: str) -> str:\n",
    "    corrected = []\n",
    "    for word in query.split():\n",
    "        try:\n",
    "            # Clean to ASCII-only before applying phonetic\n",
    "            word_ascii = word.encode(\"ascii\", \"ignore\").decode(\"ascii\").lower()\n",
    "            code = dmetaphone(word_ascii)\n",
    "            corrected_word = phonetic_dict.get(code, word)\n",
    "            corrected.append(corrected_word)\n",
    "        except Exception:\n",
    "            corrected.append(word)  # fallback to original word on error\n",
    "    return ' '.join(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6df5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install rapidfuzz\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "fuzzy_choices = list(FILTERABLE_FIELDS)\n",
    "\n",
    "def fuzzy_correction(query: str) -> str:\n",
    "    words = query.split()\n",
    "    corrected = []\n",
    "    for word in words:\n",
    "        match, score, _ = process.extractOne(word, fuzzy_choices, scorer=fuzz.WRatio)\n",
    "        corrected.append(match if score > 80 else word)  # Threshold = 80\n",
    "    return ' '.join(corrected)\n",
    "\n",
    "# Usage Example\n",
    "#fuzzy_corrected_query = fuzzy_correction(corrected_query)\n",
    "#print(\"âœ… Fuzzy Matched Query:\", fuzzy_corrected_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91f2f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_dict_expansion(new_terms: List[str]):\n",
    "    for term in new_terms:\n",
    "        term = term.lower().strip()\n",
    "        if term not in sym_spell.words:\n",
    "            sym_spell.create_dictionary_entry(term, 5000)\n",
    "            print(f\"ðŸ“¥ Added new term: {term}\")\n",
    "\n",
    "# Example\n",
    "#dynamic_dict_expansion([\"unacademy\", \"nykaa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfeed3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”‘ TOGETHER_API_KEY set to: tgp_v1_PoHC0z_NQ9z7XluCXtUez9Jc-mV8fjDz8hmwVBccGBI\n"
     ]
    }
   ],
   "source": [
    "# %pip install python-dotenv  # Uncomment if not installed\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# âœ… Automatically load environment variables from .env\n",
    "load_dotenv(dotenv_path=\"./env.env\")\n",
    "\n",
    "TOGETHER_API_KEY = os.getenv(\"together_ai_api_key\")\n",
    "print(\"ðŸ”‘ TOGETHER_API_KEY set to:\", TOGETHER_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83982798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def together_chat_mistral(query: str) -> str:\n",
    "    url = \"https://api.together.xyz/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a query rephraser. Your ONLY task is to rephrase the given query \"\n",
    "                    \"into clean English without adding, removing, or guessing any content. \"\n",
    "                    \"Preserve all terms exactly. No tags. No classifications. No explanations.\"\n",
    "                )\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"{query}\"}\n",
    "        ],\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 100,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "\n",
    "    res = requests.post(url, headers=headers, json=payload)\n",
    "    if res.status_code == 200:\n",
    "        return res.json()['choices'][0]['message']['content'].strip()\n",
    "    else:\n",
    "        return f\"[ERROR {res.status_code}]: {res.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf14c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def run_pipeline(query: str):\n",
    "    print(f\"\\nðŸŸ¢ RAW_QUERY: {query}\")\n",
    "\n",
    "    corrected_symspell = symspell_correct(query)\n",
    "    print(f\"ðŸ”¤ SYMSPELL_CORRECTED: {corrected_symspell}\")\n",
    "\n",
    "    corrected_phonetic = phonetic_correction(corrected_symspell)\n",
    "    print(f\"ðŸ”Š PHONETIC_CORRECTED: {corrected_phonetic}\")\n",
    "\n",
    "    corrected_fuzzy = fuzzy_correction(corrected_phonetic)\n",
    "    print(f\"ðŸ”Ž FUZZY_CORRECTED: {corrected_fuzzy}\")\n",
    "\n",
    "    llm_result = together_chat_mistral(corrected_fuzzy)\n",
    "    print(f\"ðŸ¤– LLM_NORMALIZED:\\n{llm_result}\\n\")\n",
    "\n",
    "    return {\n",
    "        \"raw_query\": query,\n",
    "        \"symspell_corrected\": corrected_symspell,\n",
    "        \"phonetic_corrected\": corrected_phonetic,\n",
    "        \"fuzzy_corrected\": corrected_fuzzy,\n",
    "        \"llm_normalized\": llm_result\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bda4b0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¢ RAW_QUERY: fnd sars compny byjuz in benguluru\n",
      "ðŸ”¤ SYMSPELL_CORRECTED: and cars company by us in bengaluru\n",
      "ðŸ”Š PHONETIC_CORRECTED: and cars company by us in bengaluru\n",
      "ðŸ”Ž FUZZY_CORRECTED: and cars company by users hiring bengaluru\n",
      "ðŸ¤– LLM_NORMALIZED:\n",
      "Companies in Bangalore that offer car hiring services, as chosen by users.\n",
      "\n",
      "RAW_QUERY                : fnd sars compny byjuz in benguluru\n",
      "SYMSPELL_CORRECTED       : and cars company by us in bengaluru\n",
      "PHONETIC_CORRECTED       : and cars company by us in bengaluru\n",
      "FUZZY_CORRECTED          : and cars company by users hiring bengaluru\n",
      "LLM_NORMALIZED           : Companies in Bangalore that offer car hiring services, as chosen by users.\n",
      "\n",
      "ðŸ”„ Pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "test_query = \"fnd sars compny byjuz in benguluru\"\n",
    "output = run_pipeline(test_query)\n",
    "\n",
    "for stage, result in output.items():\n",
    "    print(f\"{stage.upper():<25}: {result}\")\n",
    "\n",
    "print(\"\\nðŸ”„ Pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "706c0662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.6872326135635376\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "query1 = \"Find SAS companies in India\"\n",
    "query2 = \"Find SaaS startups in India\"\n",
    "\n",
    "# Get embeddings\n",
    "emb1 = model.encode(query1, convert_to_tensor=True)\n",
    "emb2 = model.encode(query2, convert_to_tensor=True)\n",
    "\n",
    "# Check similarity\n",
    "similarity = util.pytorch_cos_sim(emb1, emb2)\n",
    "print(\"Similarity Score:\", similarity.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8a0ba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SymSpell Corrected Query: find companies in delhi for health\n",
      "Rewritten Query: 'Fidn companeis in Delhi for healt'\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "def rewrite_query(user_query):\n",
    "    prompt = f\"Fix and rewrite the following user search query into correct English and with proper keywords:\\n'{user_query}'\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs, max_new_tokens=30)\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# âœ… Example\n",
    "query = \"Fidn companeis in Delhi for healt\"\n",
    "bert_query = rewrite_query(query)\n",
    "sym_query = symspell_correct(query)\n",
    "print(\"âœ… SymSpell Corrected Query:\", sym_query)\n",
    "print(\"Rewritten Query:\", bert_query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
