{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d483c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import sys, os\n",
    "\n",
    "try:\n",
    "    # ✅ Running from a Python script (.py file)\n",
    "    base_path = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "except NameError:\n",
    "    # ✅ Running from a Jupyter notebook (__file__ is not defined)\n",
    "    base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "SRC_PATH = os.path.join(base_path)\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "    print(f\"✅ SRC path added: {SRC_PATH}\")\n",
    "else:\n",
    "    print(f\"🔁 SRC path already in sys.path: {SRC_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agents/restaurant/slot_collector_agent.py\n",
    "\n",
    "from langchain_together import ChatTogether\n",
    "from langchain.agents import create_structured_chat_agent, AgentExecutor\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import StructuredTool\n",
    "from schema.slot_schema import SlotCollectorInput, SlotCollectorOutput\n",
    "\n",
    "# Dummy logic (LLM will actually parse)\n",
    "def extract_user_info(query: str) -> dict:\n",
    "    return {\n",
    "        \"name\": \"Rahul\",\n",
    "        \"phone\": \"9876543210\",\n",
    "        \"table_number\": 4,\n",
    "        \"number_of_people\": 2\n",
    "    }\n",
    "\n",
    "slot_collector_tool = StructuredTool.from_function(\n",
    "    name=\"slot_collector_tool\",\n",
    "    description=\"Extracts name, phone, table number, and party size from the user's input.\",\n",
    "    func=extract_user_info,\n",
    "    args_schema=SlotCollectorInput,\n",
    "    return_schema=SlotCollectorOutput\n",
    ")\n",
    "\n",
    "# Agent Setup\n",
    "llm = ChatTogether(model=\"mistralai/Mistral-7B-Instruct-v0.2\", api_key=os.getenv(\"together_ai_api_key\"), temperature=0)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You're a helpful slot-filler agent for a restaurant. You need to extract the user's name, phone, table number, and how many people are dining.\n",
    "\n",
    "Always call `slot_collector_tool` with the query input.\n",
    "\n",
    "Example:\n",
    "{{\"action\": \"slot_collector_tool\", \"action_input\": {{\"query\": \"<user message>\"}}}}\n",
    "\n",
    "Begin!\n",
    "\n",
    "Human: {input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "slot_agent = create_structured_chat_agent(\n",
    "    llm=llm,\n",
    "    tools=[slot_collector_tool],\n",
    "    prompt=prompt_template\n",
    ")\n",
    "\n",
    "slot_executor = AgentExecutor(agent=slot_agent, tools=[slot_collector_tool], verbose=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
