{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94714258",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%pip install -U langchain langchain-core langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594a8f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SRC path added: /home/prashant-agrawal/projects/netflix_talk2data/src\n"
     ]
    }
   ],
   "source": [
    "# Ensure src/ is in sys.path so 'tools' can be imported\n",
    "# %%\n",
    "import sys, os\n",
    "try:\n",
    "    # ‚úÖ Running from a Python script (.py file)\n",
    "    TOOLS_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "except NameError:\n",
    "    # ‚úÖ Running from a Jupyter notebook (__file__ is not defined)\n",
    "    TOOLS_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "SRC_PATH = os.path.join(TOOLS_PATH)\n",
    "\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "    print(f\"‚úÖ SRC path added: {SRC_PATH}\")\n",
    "else:\n",
    "    print(f\"üîÅ SRC path already in sys.path: {SRC_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b71878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Path : /home/prashant-agrawal/projects/netflix_talk2data/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(f\"Current Path : {sys.path[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba47942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Enhancer Agent --\n",
    "# This script sets up an agent that enhances queries by extracting structured metadata and filters.\n",
    "# It uses a set of tools to analyze and transform vague or unstructured queries into clear, structured metadata.\n",
    "# The agent is designed to work with the LangChain framework and utilizes OpenAI's GPT-4 model.\n",
    "# The agent is capable of using various tools such as keyword extractors, numeric constraint extractors, and category classifiers.\n",
    "\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.agents import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command\n",
    "from typing import Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68f87690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ SRC path already in sys.path: /home/prashant-agrawal/projects/netflix_talk2data/src\n"
     ]
    }
   ],
   "source": [
    "# üîÅ Import all tools from registry\n",
    "from tools.enhancer_tools_registry import (\n",
    "    keyword_extractor_tool,\n",
    "    extract_numeric_constraints_tool,\n",
    "    filter_composer_tool\n",
    ")\n",
    "\n",
    "# Define tools for the enhancer agent\n",
    "enhancer_tools = [\n",
    "    keyword_extractor_tool,\n",
    "    extract_numeric_constraints_tool,\n",
    "    filter_composer_tool\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9905de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define tool names for the agent\n",
    "tool_names = [tool.name for tool in enhancer_tools]\n",
    "\n",
    "# Define the tool descriptions\n",
    "tool_descriptions = [tool.description for tool in enhancer_tools]\n",
    "\n",
    "# Build readable tool help text for the prompt\n",
    "tool_help_text = \"\\n\".join(\n",
    "    [f\"{i+1}. {tool.name} - {tool.description}\" for i, tool in enumerate(enhancer_tools)]\n",
    ")\n",
    "\n",
    "\n",
    "# Define system prompt used during agent creation\n",
    "\n",
    "enhancer_agent_prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"You are a Query Enhancer Agent.\n",
    "\n",
    "Rules:\n",
    "- Do not ask follow-up questions.\n",
    "- Infer likely meanings when user input is ambiguous.\n",
    "- Your output should be a standalone, precise query in natural language.\n",
    "- Do not include explanations or formatting like ‚ÄúHere‚Äôs the improved query.‚Äù\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Question: {input}  \n",
    "Thought: <think about which tool to call first>  \n",
    "Action: <tool name, from [{tool_names}]>  \n",
    "Action Input: <JSON or text input for that tool>  \n",
    "Observation: <its output>  \n",
    "‚Ä¶ (repeat Thought/Action/Observation as needed) ‚Ä¶  \n",
    "Thought: I have all the pieces.  \n",
    "Final Answer: {{\"enhanced_query\": \"<refined NL query>\",\n",
    "                \"filters\": <dict of all filters>,\n",
    "                \"k\": <integer>}}\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}  \n",
    "{agent_scratchpad}\"\"\"\n",
    ")\n",
    "\n",
    "# Format the prompt with tool descriptions and names\n",
    "formatted_prompt = enhancer_agent_prompt_template.partial(\n",
    "    tools=tool_help_text,\n",
    "    tool_names=\", \".join(tool.name for tool in enhancer_tools)\n",
    ")\n",
    "\n",
    "# üîß Define the React-style agent\n",
    "llm = ChatOpenAI(model=\"gpt-4o\",temperature=0)  # Or use your preferred model\n",
    "\n",
    "\n",
    "# Create the agent\n",
    "enhancer_agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=enhancer_tools,\n",
    "    prompt=formatted_prompt,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96e729ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should first extract relevant keywords related to the company fields.  \n",
      "Action: keyword_extractor  \n",
      "Action Input: \"Find 5 B2B SaaS startups in India\"  \u001b[0m\u001b[36;1m\u001b[1;3m{'industry_sector': ['saas', 'b2b']}\u001b[0m\u001b[32;1m\u001b[1;3mI should extract any numeric constraints from the query.  \n",
      "Action: extract_numeric_constraints  \n",
      "Action Input: \"Find 5 B2B SaaS startups in India\"  \u001b[0m\u001b[33;1m\u001b[1;3m{}\u001b[0m\u001b[32;1m\u001b[1;3mI should now compose the filters using the extracted information.  \n",
      "Action: filter_composer  \n",
      "Action Input: {\"industry_sector\": [\"saas\", \"b2b\"], \"location\": \"India\"}  \u001b[0m\u001b[38;5;200m\u001b[1;3m{}\u001b[0m\u001b[32;1m\u001b[1;3mFind five B2B SaaS startups located in India.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3mFind five B2B SaaS startups located in India.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3mFind five B2B SaaS startups located in India.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3mI have all the pieces.  \n",
      "Final Answer: {\"enhanced_query\": \"Find five B2B SaaS startups located in India.\", \"filters\": {\"industry_sector\": [\"saas\", \"b2b\"], \"location\": \"India\"}, \"k\": 5}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\"enhanced_query\": \"Find five B2B SaaS startups located in India.\", \"filters\": {\"industry_sector\": [\"saas\", \"b2b\"], \"location\": \"India\"}, \"k\": 5}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "executor = AgentExecutor(agent=enhancer_agent, tools=enhancer_tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "Find 5 B2B SaaS startups in India\"\"\"\n",
    "\n",
    "result = executor.invoke({\"input\": query})\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd1f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ SRC path already in sys.path: /home/prashant-agrawal/projects/netflix_talk2data/src\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, List, Literal\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.types import Command\n",
    "from schema.agent_state import AgentState\n",
    "from agents.enhancer_agent import enhancer_agent\n",
    "\n",
    "def normalize_messages(raw_msgs: List[Any]) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Turn any HumanMessage objects into plain dicts {\"role\",\"content\"},\n",
    "    and pass through existing dicts as-is.\n",
    "    \"\"\"\n",
    "    normalized = []\n",
    "    for m in raw_msgs:\n",
    "        if isinstance(m, HumanMessage):\n",
    "            normalized.append({\n",
    "                \"role\": m.name,       # who spoke\n",
    "                \"content\": m.content  # what they said\n",
    "            })\n",
    "        else:\n",
    "            normalized.append(m)     # assume it's already a dict\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def enhancer_node(state: AgentState) -> Command[Literal[\"supervisor\"]]:\n",
    "    # 1) Normalize history\n",
    "    msgs = normalize_messages(state.get(\"messages\", []))\n",
    "\n",
    "    # 2) Extract user input\n",
    "    user_input = \"\"\n",
    "    for m in reversed(msgs):\n",
    "        if m.get(\"role\") == \"user\":\n",
    "            user_input = m[\"content\"]\n",
    "            break\n",
    "    print(f\"\\n[DEBUG] Enhancer Node received user_input: {user_input}\")\n",
    "\n",
    "    # 3) Stream the agent\n",
    "    actions: List[str] = []\n",
    "    observations: List[str] = []\n",
    "    final_output: Any = None\n",
    "\n",
    "    payload = {\"input\": user_input, \"intermediate_steps\": []}\n",
    "    print(f\"[DEBUG] Enhancer payload: {payload}\")\n",
    "\n",
    "    for step in enhancer_agent.stream(payload):\n",
    "        if isinstance(step, AgentAction):\n",
    "            print(f\"[DEBUG] AgentAction: {step.log}\")\n",
    "            actions.append(str(step.log))\n",
    "        elif isinstance(step, AgentFinish):\n",
    "            print(f\"[DEBUG] AgentFinish output: {step.return_values.get('output')}\")\n",
    "            final_output = step.return_values.get(\"output\")\n",
    "        else:\n",
    "            print(f\"[DEBUG] Observation: {step}\")\n",
    "            observations.append(str(step))\n",
    "\n",
    "    # 4) Parse final_output\n",
    "    print(f\"[DEBUG] raw final_output: {final_output}\")\n",
    "    if isinstance(final_output, dict):\n",
    "        enhanced_query = final_output.get(\"enhanced_query\", \"\")\n",
    "        filters        = final_output.get(\"filters\", {})\n",
    "        k              = final_output.get(\"k\", None)\n",
    "        msg_text       = str(final_output)\n",
    "    else:\n",
    "        enhanced_query = \"\"\n",
    "        filters        = {}\n",
    "        k              = None\n",
    "        msg_text       = str(final_output) if final_output is not None else \"\"\n",
    "\n",
    "    # 5) Log summary\n",
    "    new_actions      = state.get(\"actions\", []) + actions + [\"Enhancer completed\"]\n",
    "    new_observations = (\n",
    "        state.get(\"observations\", [])\n",
    "        + observations\n",
    "        + [\n",
    "            f\"Enhanced Query: {enhanced_query}\",\n",
    "            f\"Filters: {filters}\",\n",
    "            f\"k: {k}\",\n",
    "        ]\n",
    "    )\n",
    "    print(f\"[DEBUG] Parsed enhanced_query: {enhanced_query}\")\n",
    "    print(f\"[DEBUG] Parsed filters: {filters}\")\n",
    "    print(f\"[DEBUG] Parsed k: {k}\")\n",
    "\n",
    "    # 6) Append message and return\n",
    "    msgs.append({\"role\": \"enhancer\", \"content\": msg_text})\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\":       msgs,\n",
    "            \"enhanced_query\": enhanced_query,\n",
    "            \"filters\":        filters,\n",
    "            \"k\":              k,\n",
    "            \"actions\":        new_actions,\n",
    "            \"observations\":   new_observations,\n",
    "            \"agent_name\":     \"enhancer\",\n",
    "        },\n",
    "        goto=\"supervisor\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
