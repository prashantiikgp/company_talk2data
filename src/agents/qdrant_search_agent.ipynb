{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0ad21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” SRC path already in sys.path: /home/prashant-agrawal/projects/netflix_talk2data/src\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import sys, os\n",
    "try:\n",
    "    # âœ… Running from a Python script (.py file)\n",
    "    TOOLS_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\",))\n",
    "except NameError:\n",
    "    # âœ… Running from a Jupyter notebook (__file__ is not defined)\n",
    "    TOOLS_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "SRC_PATH = os.path.join(TOOLS_PATH)\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "    print(f\"âœ… SRC path added: {SRC_PATH}\")\n",
    "else:\n",
    "    print(f\"ðŸ” SRC path already in sys.path: {SRC_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486622a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Import LangChain and your tools\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.agents import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command\n",
    "from typing import Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e6f980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” SRC path already in sys.path: /home/prashant-agrawal/projects/netflix_talk2data/src\n",
      "ðŸ“Œ Collection Name: indian_startups\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” Import all tools from registry\n",
    "from tools.qdrant_tools_registry import qdrant_search_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425184d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools for the enhancer agent\n",
    "qdrant_agent_tools = [\n",
    "    qdrant_search_tool,\n",
    "]\n",
    "\n",
    "# Define tool names for the agent\n",
    "tool_names = [tool.name for tool in qdrant_agent_tools]\n",
    "\n",
    "# Define the tool descriptions\n",
    "tool_descriptions = [tool.description for tool in qdrant_agent_tools]\n",
    "\n",
    "# Build readable tool help text for the prompt\n",
    "tool_help_text = \"\\n\".join(\n",
    "    [f\"{i+1}. {tool.name} - {tool.description}\" for i, tool in enumerate(qdrant_agent_tools)]\n",
    ")\n",
    "\n",
    "# Define system prompt used during agent creation\n",
    "qdrant_agent_prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Role:\n",
    "You are the Qdrant Search Tool, a micro-service that combines high-fidelity vector embeddings with rich, structured metadata filtering to retrieve the most relevant records from a Qdrant collection.\n",
    "\n",
    "Description & Purpose:\n",
    "- Given a natural-language query, an optional dictionary of filters (exact matches or numeric ranges), and a desired result count k, your job is to:\n",
    "    - Embed the query via OpenAI.\n",
    "    - Translate filters into Qdrant payload conditions.\n",
    "    - Execute a hybrid semantic + metadata search.\n",
    "    - Return the top-k hits, each with its id, similarity score, and full payload metadata.\n",
    "\n",
    "Inputs (Parameters):\n",
    "- query (string): free-text search string.\n",
    "- filters (dict): e.g.\n",
    "    Exact: {{ \"state\": \"delhi\", \"industry_sector\": \"saas\" }}\n",
    "    Range: {{ \"year_founded\": {{\"gte\": 2000, \"lte\": 2010}} }}\n",
    "- k (integer): the number of top results to return.\n",
    "\n",
    "Examples:\n",
    "Pure semantic (no filters)\n",
    "qdrant_search(\n",
    "    query=\"emerging agritech startups\",\n",
    "    filters=None,\n",
    "    k=5\n",
    ")\n",
    "# â†’ returns top-5 agritech vectors by relevance\n",
    "\n",
    "Metadata only\n",
    "qdrant_search(\n",
    "    query=\"\",\n",
    "    filters={{ \"state\": \"karnataka\", \"industry_sector\": \"fintech\" }},\n",
    "    k=10\n",
    ")\n",
    "# â†’ returns any fintech startups in Karnataka, ordered by vectorâ€default rank\n",
    "\n",
    "Hybrid (semantic + filters + range)\n",
    "qdrant_search(\n",
    "    query=\"best B2B platforms\",\n",
    "    filters={{ \n",
    "        \"state\": \"delhi\",\n",
    "        \"year_founded\": {{\"gte\": 2015}},\n",
    "        \"industry_sector\": \"saas\"\n",
    "    }},\n",
    "    k=3\n",
    ")\n",
    "# â†’ returns top-3 SaaS B2B startups in Delhi founded â‰¥2015\n",
    "\n",
    "Guidelines & Constraints:\n",
    "- Must apply both vector similarity and all payload filters.\n",
    "- For textual filters use exact keyword match.\n",
    "- For numeric filters support gte / lte semantics.\n",
    "- If filters=None, perform a pure semantic lookup.\n",
    "- Always return at most k results.\n",
    "- Never omit an entryâ€™s payload.\n",
    "- Ensure consistent lower-casing of filter values and field names.\n",
    "- Never return more than k results, even if multiple entries have the same score.\n",
    "- If no results match, return an empty list [].\n",
    "\n",
    "**Output Format:**\n",
    "- The final answer MUST be a valid Python dictionary (not a JSON string).\n",
    "- Do NOT wrap the output in quotes or format as a string.\n",
    "- Example:\n",
    "    Final Answer: [\n",
    "        {{\n",
    "            \"id\": \"company_123\",\n",
    "            \"score\": 0.92,\n",
    "            \"payload\": {{\n",
    "                \"company_name\": \"Acme Corp\",\n",
    "                \"industry_sector\": \"saas\",\n",
    "                ...\n",
    "            }}\n",
    "        }},\n",
    "        ...\n",
    "    ]\n",
    "\n",
    "Format:\n",
    "Question: the input query\n",
    "Thought: think step-by-step about what to extract\n",
    "Action: the tool to use, from [{tool_names}]\n",
    "Action Input: JSON string or plain text input to the tool\n",
    "Observation: result returned by the tool\n",
    "... (repeat Thought/Action/Observation as needed)\n",
    "Thought: I have gathered all necessary structured data.\n",
    "Final Answer: a Python dictionary of all extracted metadata and filters\n",
    "\n",
    "Constraints:\n",
    "- NEVER ask the user again\n",
    "- ONLY use tools\n",
    "- NEVER hallucinate missing data\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Format the prompt with tool descriptions and names\n",
    "formatted_prompt = qdrant_agent_prompt_template.partial(\n",
    "    tools=tool_help_text,\n",
    "    tool_names=\", \".join(tool.name for tool in qdrant_agent_tools),\n",
    ")\n",
    "\n",
    "# ðŸ”§ Define the React-style agent\n",
    "llm = ChatOpenAI(model=\"gpt-4o\") \n",
    "\n",
    "\n",
    "# Create the agent\n",
    "qdrant_agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=qdrant_agent_tools,\n",
    "    prompt=formatted_prompt,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ccaa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "executor = AgentExecutor(agent=qdrant_agent, \n",
    "                         tools=qdrant_agent_tools, \n",
    "                         verbose=True, \n",
    "                         handle_parsing_errors=True)\n",
    "\n",
    "import json\n",
    "structured_input = {\n",
    "    \"query\": \"D2C companies with Sequoia or Accel as lead investors and more than 200 employees\",\n",
    "    \"filters\": {\n",
    "        \"product_categories\": \"d2c\",\n",
    "        \n",
    "        },\n",
    "    \"k\": 5\n",
    "}\n",
    "\n",
    "\n",
    "# 3ï¸âƒ£ Invoke!\n",
    "result = executor.invoke({\"input\": structured_input})\n",
    "print(result[\"output\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a9468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/nodes/quadrant_search_node.py\n",
    "\n",
    "from typing import Literal, List, Any\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.types import Command\n",
    "from schema.agent_state import AgentState\n",
    "\n",
    "# Make sure you have already created your Reactâ€‘style Qdrant agent somewhere:\n",
    "# from src.agents.qdrant_search_agent import qdrant_search_agent\n",
    "\n",
    "def quadrant_search_node(state: AgentState) -> Command[Literal[\"__end__\"]]:\n",
    "    \"\"\"\n",
    "    Reactâ€‘style Qdrant Search Node:\n",
    "    \n",
    "    1. Reads `enhanced_query`, `filters`, and `k` from AgentState.\n",
    "    2. Streams the `qdrant_search_agent` (verbose=False) to capture:\n",
    "       - AgentAction steps (which tool it called)\n",
    "       - Intermediate observations (tool outputs)\n",
    "       - Final AgentFinish output (a Python dict)\n",
    "    3. Parses that dict into:\n",
    "       - `results`        â†’ list of hit dictionaries\n",
    "       - `reasoning`      â†’ agentâ€™s summary of what it did\n",
    "    4. Appends a full trace into `actions` and `observations`\n",
    "    5. Updates AgentState with:\n",
    "       â€¢ `messages` (appends the raw dict as a HumanMessage)  \n",
    "       â€¢ `retrieved_results` (the list of hits)  \n",
    "       â€¢ `final_response` (the reasoning string)  \n",
    "       â€¢ `actions` & `observations` (full logs)  \n",
    "       â€¢ `agent_name` set to `\"qdrant_search\"`  \n",
    "    6. Returns `goto=\"__end__\"` to terminate the workflow.\n",
    "    \"\"\"\n",
    "\n",
    "    # â”€â”€â”€ Disable builtâ€‘in verbose logging so we can capture our own logs â”€â”€â”€â”€\n",
    "    qdrant_search_agent.verbose = False\n",
    "\n",
    "    # â”€â”€â”€ Prepare log collectors for this node invocation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    actions: List[str] = []\n",
    "    observations: List[str] = []\n",
    "    final_output: Any = None\n",
    "\n",
    "    # â”€â”€â”€ Build the payload for the Reactâ€‘style agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    payload = {\n",
    "        \"messages\": state.get(\"messages\", []),\n",
    "        \"enhanced_query\": state.get(\"enhanced_query\"),\n",
    "        \"filters\": state.get(\"filters\"),\n",
    "        \"k\": state.get(\"k\"),\n",
    "    }\n",
    "\n",
    "    # â”€â”€â”€ Stream through the agentâ€™s Thoughtâ†’Actionâ†’Observation loop â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    for step in qdrant_search_agent.stream(payload):\n",
    "        if isinstance(step, AgentAction):\n",
    "            # Agent decided on a tool call or its own internal reasoning step\n",
    "            actions.append(str(step.log))\n",
    "        elif isinstance(step, AgentFinish):\n",
    "            # Agent has finished; expect a Python dict in `output`\n",
    "            final_output = step.return_values.get(\"output\")\n",
    "        else:\n",
    "            # Intermediate tool output (e.g. the raw DB results or metadata)\n",
    "            observations.append(str(step))\n",
    "\n",
    "    # â”€â”€â”€ Parse the final output dict (or fall back to empty) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if isinstance(final_output, dict):\n",
    "        results = final_output.get(\"results\", [])\n",
    "        reasoning = final_output.get(\"reasoning\", \"\")\n",
    "        message_content = str(final_output)\n",
    "    else:\n",
    "        # Fallback if no dict was returned\n",
    "        results = []\n",
    "        reasoning = \"\"\n",
    "        message_content = str(final_output) if final_output is not None else \"\"\n",
    "\n",
    "    # â”€â”€â”€ Append a completion marker and summary to the logs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    new_actions = (\n",
    "        state.get(\"actions\", [])\n",
    "        + actions\n",
    "        + [\"Qdrant Search agent completed\"]\n",
    "    )\n",
    "    new_observations = (\n",
    "        state.get(\"observations\", [])\n",
    "        + observations\n",
    "        + [\n",
    "            f\"Results count: {len(results)}\",\n",
    "            f\"Reasoning: {reasoning}\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # â”€â”€â”€ Return the updated AgentState and signal graph termination â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    return Command(\n",
    "        update={\n",
    "            # 1) Append the raw final_output dict as a chat message\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=message_content, name=\"qdrant_search\")\n",
    "            ],\n",
    "            # 2) Store structured results and reasoning\n",
    "            \"retrieved_results\": results,\n",
    "            \"final_response\": reasoning,\n",
    "            # 3) Persist full trace logs\n",
    "            \"actions\": new_actions,\n",
    "            \"observations\": new_observations,\n",
    "            # 4) Label which agent just ran\n",
    "            \"agent_name\": \"qdrant_search\",\n",
    "        },\n",
    "        goto=\"__end__\"  # Terminates the StateGraph\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
